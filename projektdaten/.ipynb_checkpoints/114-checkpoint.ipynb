{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1d2325-31a8-4b90-93a6-87620fc568b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ausgewählte Features: Index(['Sex', 'Age', 'Number_of_Main_Meals_Daily', 'Smoking',\n",
      "       'Calculation_of_Calorie_Intake', 'Physical_Excercise',\n",
      "       'Type_of_Transportation_Used'],\n",
      "      dtype='object')\n",
      "[[0.    0.612 0.388 0.   ]]\n",
      "Document id: 1\n",
      "Predicted class: Normalgewicht\n",
      "True class: Normalgewicht\n",
      "Explanation for class Normalgewicht\n",
      "('Age <= -0.82', 0.4116342741902539)\n",
      "('-0.93 < Frequency_of_Consuming_Vegetables <= -0.19', 0.04583713655558833)\n",
      "('-1.36 < Height <= 0.21', 0.033552306389893434)\n",
      "('-1.10 < Number_of_Main_Meals_Daily <= 0.21', 0.027996545793167918)\n",
      "('-1.52 < Overweight_Obese_Family <= 0.66', 0.0030420171323058093)\n",
      "Explanation for class Übergewicht\n",
      "('Age <= -0.82', -0.16674160498869184)\n",
      "('-0.93 < Frequency_of_Consuming_Vegetables <= -0.19', 0.04901520693182352)\n",
      "('-1.36 < Height <= 0.21', 0.02750351852928668)\n",
      "('-1.52 < Overweight_Obese_Family <= 0.66', -0.005661832576923768)\n",
      "('-1.10 < Number_of_Main_Meals_Daily <= 0.21', 0.0040734446600769825)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Schritt 1: Daten laden und vorbereiten\n",
    "file_path = \"data/Obesity_Dataset_FE_WOBMI.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Ziel- und Feature-Spalten definieren\n",
    "target_column = 'Class'\n",
    "X = data.drop(columns=[target_column])  # Features\n",
    "y = data[target_column]  # Zielvariable\n",
    "\n",
    "# Klassenlabels auf 0-basierte Indizes umstellen\n",
    "y = y - y.min()\n",
    "\n",
    "# Schritt 2: Daten in Training und Test aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Daten skalieren\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Benutzerdefinierte Klassenlabels\n",
    "class_names = [\"Untergewicht\", \"Normalgewicht\", \"Übergewicht\", \"Adipositas\"]\n",
    "feature_names = [\"Sex\", \"Age\",\t\"Height\", \"Overweight_Obese_Family\", \"Consumption_of_Fast_Food\", \"Frequency_of_Consuming_Vegetables\", \"Number_of_Main_Meals_Daily\",\t\"Food_Intake_Between_Meals\", \"Smoking\",\t\"Liquid_Intake_Daily\",\t\"Calculation_of_Calorie_Intake\", \"Physical_Excercise\",\t\"Schedule_Dedicated_to_Technology\",\t\"Type_of_Transportation_Used\",\t\"FoodConsumption\", \"Activity\"]\n",
    "\n",
    "\n",
    "# Schritt 3: Feature-Auswahl\n",
    "selector = SelectFromModel(LinearSVC(penalty=\"l2\", dual=False, random_state=42)).fit(X_train, y_train)\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Ausgewählte Features:\", selected_features)\n",
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Sicherstellen, dass Features ausgewählt wurden\n",
    "if X_train.shape[1] == 0:\n",
    "    raise ValueError(\"Keine Features nach der Auswahl übrig. Überprüfen Sie die Feature-Auswahl.\")\n",
    "\n",
    "# Schritt 4: Verschiedene Modelle definieren\n",
    "models = {\n",
    "    #'SVM': {\n",
    "    #  'model': Pipeline([('classification', LinearSVC(dual=False, max_iter=1000, random_state=42))]),\n",
    "    #  'params': {'classification__C': [0.01, 0.1, 1, 10]}\n",
    "    #},\n",
    "    'Random Forest': {\n",
    "        'model': Pipeline([('classification', RandomForestClassifier(random_state=42))]),\n",
    "        'params': {'classification__n_estimators': [50, 100, 200], 'classification__max_depth': [None, 10, 20]}\n",
    "    },\n",
    "    #'Logistic Regression': {\n",
    "    #    'model': Pipeline([('classification', LogisticRegression(max_iter=500, random_state=42))]),\n",
    "    #    'params': {'classification__C': [0.01, 0.1, 1, 10]}\n",
    "    #},\n",
    "    \n",
    "}\n",
    "\n",
    "# Schritt 5: Hyperparameter-Tuning und Training\n",
    "best_models = {}\n",
    "for name, config in models.items():\n",
    "    grid_search = GridSearchCV(config['model'], config['params'], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    best_models[name] = grid_search\n",
    "\n",
    "\n",
    "def plot_learning_curves(model, X_train, y_train, X_dev, y_dev):\n",
    "    train_fs, dev_fs = [], []\n",
    "    for m in range(10, X_train.shape[0],10):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.best_estimator_.predict(X_train[:m])\n",
    "        y_dev_predict = model.best_estimator_.predict(X_dev)\n",
    "        train_fs.append(f1_score(y_train[:m], y_train_predict,average='weighted'))\n",
    "        dev_fs.append(f1_score(y_dev, y_dev_predict, average='weighted'))\n",
    "        #print(\"\\nKlassifikationsbericht:\\n\", classification_report(y_dev, y_dev_predict, target_names=class_labels))\n",
    "    plt.plot(train_fs, \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(dev_fs, \"b-\", linewidth=3, label=\"dev\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Index der Trainingsiteration')\n",
    "    plt.ylabel('F-Score des Lerners')\n",
    "    plt.show()  # Zeigt den Plot an\n",
    "\n",
    "\n",
    "# Schritt 6: Ergebnisse der besten Modelle auswerten\n",
    "#for name, grid_search in best_models.items():\n",
    "    #plot_learning_curves(grid_search, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Schritt 7: Modell evaluieren\n",
    "for name, grid_search in best_models.items():\n",
    "    #Pipeline definieren\n",
    "    c = grid_search\n",
    "\n",
    "    # Pipeline trainieren\n",
    "    c.fit(X_train, y_train)\n",
    "\n",
    "    # Wahrscheinlichkeiten für ein Testbeispiel vorhersagen\n",
    "    idx = 1\n",
    "    print(c.predict_proba([X_test[idx]]).round(3))\n",
    "\n",
    "    # LIME Tabular Explainer initialisieren\n",
    "    explainer = LimeTabularExplainer(\n",
    "        training_data=X_train,  # Trainingsdaten als NumPy-Array\n",
    "        feature_names=feature_names,  # Spaltennamen\n",
    "        class_names=class_names,  # Klassenlabels\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    # Testbeispiel auswählen\n",
    "    sample = X_test[idx]  # Zeile als NumPy-Array\n",
    "\n",
    "    # Erklärung mit LIME für tabellarische Daten erzeugen\n",
    "    exp = explainer.explain_instance(\n",
    "    sample,\n",
    "    c.predict_proba,\n",
    "    num_features=5, # Anzahl der erklärbaren Features\n",
    "    top_labels=2\n",
    "    )\n",
    "\n",
    "    # Ausgabe\n",
    "    print('Document id: %d' % idx)\n",
    "    print('Predicted class:', class_names[c.predict([X_test[idx]])[0]])\n",
    "    print('True class:', class_names[y_test.iloc[idx]])\n",
    "\n",
    "    # Welche beiden Labels wurden vorgeschlagen?\n",
    "    top_labels= exp.available_labels()\n",
    "\n",
    "\n",
    "    # Ausgabe textuell\n",
    "\n",
    "    print ('Explanation for class %s' % class_names[top_labels[0]])\n",
    "    print ('\\n'.join(map(str, exp.as_list(top_labels[0]))))\n",
    "\n",
    "    print ('Explanation for class %s' % class_names[top_labels[1]])\n",
    "    print ('\\n'.join(map(str, exp.as_list(top_labels[1]))))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc74c3c-6089-4464-9858-2b365c8229b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
