{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f1c764",
   "metadata": {},
   "source": [
    "# Datentransformation\n",
    "\n",
    "Bestimmte Auswertungen und Visualisierungen sind viel einfacher, wenn die Daten in einer bestimmten Struktur angeordnet sind. Erste Beispiele haben wir im Kapitel Datenexploration gesehen:\n",
    "- Wenn wir die Daten sortieren, dann ist es einfach auf die größten/kleinsten Einträge zuzugreifen\n",
    "- Wenn wir die Daten gruppieren, dann können wir einfach Statistiken für bestimmte Untergruppen berechnen\n",
    "\n",
    "Die vorherigen Operationen ordnen die einzelnen Zeilen anders an (`sort_values`) oder fassen sie zusammen (`groupby` und `agg`) lassen aber die generelle Form des DataFrame mehr oder minder in Takt (bei Gruppierungen können Spalten hinzukommen oder wegfallen und der Index verändert werden).\n",
    "In diesem Kapitel gehen wir auf Methoden ein, die zu DataFrames mit anderem Aufbau führen, z.B.\n",
    "- Beim Pivotieren führen wir im Prinzip eine zweidimensionale Gruppierung durch, so dass aus Werten in Zeilen im Ergebnis Spalten werden (z.B. von einer Zeile pro Transporttyp (Bahn, Bus) zu einer Zeile pro Stadt mit Transporttypen als Spalten)\n",
    "- Mit `melt` erreichen wir das Gegenteil und machen aus Spalten Werte in Zeilen (z.B. aus 3 Spalten mit den 3 größten Städten pro Land werden 3 Zeilen pro Land mit je einer Stadt)\n",
    "- Mit `merge` führen wir unterschiedliche DataFrames in eins zusammen (z.B. aus Datensätzen über Städte und Liniennetze wird ein Datensatz mit mit Infos über beides)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><b>INFO</b>\n",
    "    <p>Die Übungen und Beispiele basieren auf Daten über \n",
    "    weltweite Systeme des öffentlichen Nahverkehrs von <a href=\"https://www.citylines.co\">https://www.citylines.co</a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69585004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d7a84",
   "metadata": {},
   "source": [
    "## Datensätze zusammenführen\n",
    "\n",
    "Bei der Einführung in pandas haben wir bereits einen Blick auf `pd.concat` geworfen, um DataFrames \"nebeneinander\" oder \"untereinander\" zu packen.\n",
    "\n",
    "Zur Wiederholung noch mal einfache Beispiele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]}, index=[0, 1, 2])\n",
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = pd.DataFrame({'a': [7, 8, 9], 'b': [10, 11, 12]}, index=[3, 4, 5])\n",
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Untereinander\" zusammenfügen:\n",
    "dfab = pd.concat([dfa, dfb])\n",
    "dfab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d073553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Nebeneinander\" zusammenfügen\n",
    "dfc = pd.DataFrame({'c': [13, 14, 15, 16, 17, 18]})\n",
    "pd.concat([dfab, dfc], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eedb8e",
   "metadata": {},
   "source": [
    "Die Besonderheit beim letzten Beispiel ist, dass wir a) gleich viele Zeilen in beiden DataFrames haben (dfab und dfc) und die Indexe übereinstimmen. Für generischere Zusammenführungen (nicht nur 1:1, sondern 1:n oder n:m) im Stile von SQL-Joins oder Excel-vlookups gibt es die Methode `merge`. Siehe den [User Guide](https://pandas.pydata.org/docs/user_guide/merging.html#) für umfangreiche Beispiele der einzelnen Methoden.\n",
    "\n",
    "Wir laden als erstes neben unserer cities-Datenbank drei weitere Datensätze:\n",
    "- `lines`: enthält die Linien (z.B. S1, Bus 42) der einzelnen Systeme\n",
    "- `transport_modes`: enthält die textuellen Bezichnungen, der verschiedenen Arten von ÖPNV-Systemen (z.B. \"tram\" (Strassenbahn) oder \"bus\")\n",
    "- `sections`: enthält Abschnitte im Liniennetz also z.B. die Schienen zwischen zwei Haltestellen\n",
    "- `section_lines`: enthält die Zuordnung der Abschnitte zur einer Linie, ggfs. mit Einschränkung des Zeitraums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('data/cities_non_zero.csv', index_col='id')\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached version of https://data.heroku.com/dataclips/pzyttqskrypbmrycmyzgfiyiazzj.csv\n",
    "# Datum: 19.07.2021\n",
    "lines = pd.read_csv(\"data/lines.csv\", index_col='id')\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached version of https://data.heroku.com/dataclips/laduqgisvogcjargoqgcvgdjibxl.csv\n",
    "# Datum: 19.07.2021\n",
    "transport_modes = pd.read_csv('data/transport_modes.csv', index_col='id')\n",
    "transport_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached version of https://data.heroku.com/dataclips/jpimoyzuunvntdmjgheiscrzahls.csv\n",
    "# Datum: 19.07.2021\n",
    "sections = pd.read_csv(\"data/sections.csv\", index_col='id')\n",
    "sections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached version of https://data.heroku.com/dataclips/egetzfbhwqhqjbpedplrgppjlerc.csv\n",
    "# Datum: 19.07.2021\n",
    "section_lines = pd.read_csv(\"data/section_lines.csv\", index_col='id')\n",
    "section_lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f3a76",
   "metadata": {},
   "source": [
    "Die einzelnen Datensätze sind zu einem gewissen Ausmaß [normalisiert](https://de.wikipedia.org/wiki/Normalisierung_(Datenbank)). Für die Datenanalyse bevorzugen wir im Allgemeinen eine denormalisierte Form, die pro Zeile eine Beobachtung/ein Objekt mit allen zugehörigen Informationen enthält - z.B. eine Stadt mit dem Namen des zugehörigen Landes. Ausnahmen gibt es bei Speichermangel oder insbesondere, wenn die Daten für Machine Learning vorbereitet werden, wo wir bestimmte Daten wieder numerisch ähnlich einem Index kodieren. \n",
    "Im Folgenden nutzen wir die `merge`-Methode, um das `cities`-DataFrame nach und nach mit den Informationen der anderen DataFrames anzureichern. Die `merge`-Methode wird auf dem *linken* DataFrame aufgerufen und bekommt als ersten Parameter das *rechte* DataFrame. Das Ergebnis ist eine Kombination aus *linkem* und *rechtem* DataFrame, das entsprechend der weiteren Parameter zusammengesetzt wird:\n",
    "- Mit `on` wird eine Spalte angegeben, die in beiden DataFrames vorhanden sein muss - neue Zeilen entstehen aus den Kombinationen aus linken und rechten Zeilen, die in der `on`-Spalte übereinstimmen\n",
    "- Mit `left_on` und `right_on` können unterschiedliche Spaltennamen im linken und rechten DataFrame angegeben werden\n",
    "- Statt Spalten kann mit `left_index` und `right_index` auch angegeben werden, dass der Index genutzt werden soll\n",
    "- Standardmäßig werden nur Zeilen ausgegeben zu denen übereinstimmende Werte in beiden DataFrames existieren (Parameter `how='inner'`). Alternativ können alle Zeilen aus dem linken (`how='left'`), rechten (`how='right'`) oder beiden (`how='outer'`) DataFrames übernommen werden - die fehlenden Daten werden dann mit `np.NaN` aufgefüllt.\n",
    "- Mit `suffixes` kann eine Liste von Strings übergeben werden, die an Spaltennamen gehängt werden, wenn die Namen in beiden DataFrames vorkommen\n",
    "\n",
    "Als Erstes überlegen wir das Ziel der Analyse: Wir wollen pro Stadt rausfinden, wie viele Kilometer auf verschiedene Transportarten (Schiene, Bus, etc.) fallen.\n",
    "\n",
    "Wir fangen \"unten\" bei den Streckenabschnitten an und kommen dann zu den Städten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfügen von sections und zugehöriger Line\n",
    "line_sections = sections.merge(section_lines, left_index=True, right_on='section_id', suffixes=['','_sections'])\n",
    "# Anfügen der Infos aus lines\n",
    "\n",
    "line_sections = line_sections.merge(lines, left_on='line_id', suffixes=['','_lines'], right_index=True)\n",
    "line_sections.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba5282",
   "metadata": {},
   "source": [
    "Nun können wir die Abschnitte auf Transport-Modus-Ebene agreggieren. Dabei filtern wir auch alle Zuordnungen raus, die entweder ein Startdatum (`fromyear`) in der Zukunft oder ein Enddatum (`toyear`) in der Vergangenheit haben. Ebenso gehen wir bei `opening` und `closing` der Sections vor. Da wir hier viele `NaN`-Werte haben ersetzen wir mit passenden \"Randwerten\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f400c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ersetzen der NaNs mit passenden Randwerten\n",
    "# Wir wählen die Werte so, dass bei NaN angenommen wird:\n",
    "# - die Zuordnung besteht schon immer (Jahr 0)\n",
    "# - und bis in alle Ewigkeit (Jahr 9999)\n",
    "line_sections['fromyear'].fillna(value=0, inplace=True)\n",
    "line_sections['toyear'].fillna(value=9999, inplace=True)\n",
    "# Ausfiltern der Zuordnungen, die nicht aktuell sind\n",
    "year = 2021\n",
    "line_sections = line_sections[(line_sections['fromyear'] <= year) & (line_sections['toyear'] >= year)]\n",
    "\n",
    "# Gleiches Vorgehen bezüglich opening und closing der sections\n",
    "line_sections['opening'].fillna(value=0, inplace=True)\n",
    "line_sections['closure'].fillna(value=9999, inplace=True)\n",
    "# Ausfiltern der Sections, die nicht aktuell sind\n",
    "year = 2021\n",
    "line_sections = line_sections[(line_sections['opening'] <= year) & (line_sections['closure'] >= year)]\n",
    "\n",
    "\n",
    "\n",
    "# Reduzieren des Datensatzes auf Stadt, Section und Transport-Modus\n",
    "# Entfernen von Duplikaten - ein Abschnitt kann von Mehreren Linien\n",
    "# befahren werden und würde sonst doppelt gezählt\n",
    "line_sections = line_sections[['city_id', 'section_id', 'transport_mode_id', 'length']].drop_duplicates()\n",
    "\n",
    "# Aggregation auf Transport-Modus-Ebene\n",
    "mode_lengths = line_sections.groupby(['city_id', 'transport_mode_id'], as_index=False).agg({'length': 'sum'})\n",
    "mode_lengths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577dde6",
   "metadata": {},
   "source": [
    "Nun fügen wir die Labels der Transport-Modi hinzu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb4f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_lengths = mode_lengths.merge(transport_modes, left_on='transport_mode_id', right_index=True)\n",
    "mode_lengths.rename(columns={'name': 'transport_mode'},inplace=True)\n",
    "mode_lengths.drop(columns=['transport_mode_id'],inplace=True)\n",
    "mode_lengths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb6a63",
   "metadata": {},
   "source": [
    "Und schließlich die Transportmodi an die Städte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_modes = cities.merge(mode_lengths, left_index=True,right_on='city_id')\n",
    "city_modes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8549630",
   "metadata": {},
   "source": [
    "Hier sehen wir schon einen Nachteil der denormalisierten Daten: die Gesamtlänge (`length_km`) des Systems der Stadt wird zu jeder Transportart gespeichert:\n",
    "- Man muss sich merken, bzw. dokumentieren, dass die Länge sich auf die gesamte Stadt und nicht auf das System bezieht\n",
    "- Bei einer Aggregation, darf man keinesfalls die Summe der Längen bilden\n",
    "\n",
    "Ferner ist zu beachten, dass ein Eintrag im DataFrame jetzt keine Stadt mehr beschreibt, sondern viel mehr eine Kombination aus Stadt und Transport-Modus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058fbe5",
   "metadata": {},
   "source": [
    "Nun haben wir eine Tabelle, die wie gewünscht die Länge pro Transport-Modus je Stadt hat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b1603",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ÜBUNG: </b> Aggregation und Merging\n",
    "<p>Erstellen Sie Bar-Chart , das den Anteil der verschiedenen Transport-Modi je Land darstellt. Gehen Sie wie folgt vor:</p>\n",
    "    <ol><li>Erstellen Sie einen Datensatz mit der Gesamtlänge pro Land indem Sie nach Ländern gruppieren</li></li>\n",
    "        <li>Mergen Sie den neuen Datensatz mit einer Version von sich selbst, wo über alle Transport-Modi hinweg gruppiert wird</li>\n",
    "        <li>Erstellen Sie ein Bar-Chart, das den Anteil von `bus` am Gesamtsystem je Land ausgibt</li></ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11adae8c",
   "metadata": {},
   "source": [
    "## Pivottabellen\n",
    "\n",
    "In der vorherigen Gruppierung haben wir zwar ggfs. mehrere Linien und Abschnitte pro Stadt zusammengefasst, aber wir haben immer noch mehrere Zeilen je Stadt. Um das umgehen verwenden wir die Methode `pivot_table` ([API Referenz](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html#pandas.pivot_table)). Diese Methode ist am ähnlichsten zu dem, was viele Benutzer aus Excel oder Business-Intelligence-Tools kennen - es gibt auch die Methoden `pivot` und `stack` auf denen `pivot_table` teilweise aufbaut. Der [User Guide](https://pandas.pydata.org/docs/user_guide/reshaping.html) geht auf genauer auf die Verwendung ein.\n",
    "\n",
    "Vereinfacht gesagt kann hier zweidimensional gruppiert werden:\n",
    "- per `index`-Parameter wird angegeben welche Spalte(n) gruppiert werden sollen, um als Zeilen-Labels verwendet zu werden \n",
    "- per `columns`-Parameter wird angeben welche Spalte(n) gruppiert werden sollen, um als Spaltennamen verwendet zu werden\n",
    "- per `values` wird angebenen aus welcher Spalte die Werte zur Aggregation geholt werden sollen\n",
    "- per `aggfunc` wird angegeben wie die Werte aggregiert werden sollen\n",
    "\n",
    "Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_modes.pivot_table(index='name', columns='transport_mode', values='length', aggfunc='sum').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd74af0",
   "metadata": {},
   "source": [
    "In der Tabelle sehen wir viele `NaN` Werte - immer wenn zur Kombination Stadt und Transportmodus keine Werte vorliegen. Je nach Anwendung bietet es sich hier an einene konstanten Wert einzusetzen. In unserem Fall erscheint eine Länge von 0 als sinnvoll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_system_lengths = city_modes.pivot_table(index='name', columns='transport_mode',\n",
    "                                             values='length', aggfunc='sum',\n",
    "                                            fill_value=0.0)\n",
    "city_system_lengths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a156f4",
   "metadata": {},
   "source": [
    "An dieser Stelle bietet sich ein Test an, ob die Daten konsistent und unsere bisherigen Schritte korrekt waren. Wir wollen die Summe über alle Transportarten (generiert aus den `lines` und `sections` Tabellen) mit der Gesamtlänge im DataFrame `cities` vergleich. Wir kennen bereits die `.sum()`-Methode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_system_lengths.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d20196",
   "metadata": {},
   "source": [
    "Hierbei handelt es sich jedoch um die zeilenweisen Summen über alle Städte. `.sum()` nimmt einen Axis-Parameter und der ist als default immer 0/'rows'. Hier wollen wir jedoch die Summe über alle Spalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a248f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_system_lengths['total'] = city_system_lengths.sum(axis='columns')\n",
    "city_system_lengths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016553d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anpassen der Längen auf km um Vergleichbarkeit zu cities-Tabelle herzustellen\n",
    "city_system_lengths /= 1000.0\n",
    "# Mergen der `lengths_km` aus der cities Tabelle. Wir haben keine city_id also über Namen der Stadt\n",
    "city_system_lengths = city_system_lengths.merge(cities[['name', 'length_km']], left_index=True,right_on='name')\n",
    "city_system_lengths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_system_lengths['diff_abs'] = (city_system_lengths['total'] - city_system_lengths['length_km']).abs()\n",
    "# Anzeige der 10 Städte mit der größten Differenz\n",
    "city_system_lengths[['name', 'total', 'length_km', 'diff_abs']].sort_values('diff_abs', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04823f",
   "metadata": {},
   "source": [
    "Wie wir sehen sind hier teilweise größere Differenzen für einzelne Städte. Das ist ein durchaus typisches Phänomen bei Datensätzen, die sowohl die Detaildaten (Länge aller Sections und (indirekte) Zuordnung zu Städten) als auch schon aggregierte Daten beinhalten (Länge in cities DataFrame). Dies kann verschiedene Ursachen haben:\n",
    "- Aggregierte Daten wurden nicht aktualisiert, nachdem Detaildaten verändert wurden\n",
    "- Unterschiedliche Berechnungsweisen - wir haben hier schon einiges an Annahmen reingesteckt, z.B. bzgl. Opening, Closure und Section Zuordnungsdaten. Diese können von der Berechnung des Datenproviders abweichen\n",
    "\n",
    "Da die Abweichung auf das gesamte Datenset recht gering ist, akzeptieren wir diese Abweichung. Bis zu welchem Wert etwas gering oder akzeptabel ist. Da es uns hier nur um die Verteilung zwischen den Transportarten geht und nicht um die absoluten Werte sind wir recht grosszügig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbe947",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Abweichungen über alle Städte {city_system_lengths[\"diff_abs\"].sum() / city_system_lengths[\"total\"].sum() * 100:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc02c1",
   "metadata": {},
   "source": [
    "Sollten wir höhere Präzision brauchen können wir je nach konkreter Situation:\n",
    "- Explorative Datenanalyse der Städte mit größter Abweichung, um Ursachen einzugrenzen\n",
    "- Klärung der Berechnungslogik oder bekannter Abweichung mit Anbieter der Daten\n",
    "- Untersuchung des Codes, der die Daten berechnet\n",
    "\n",
    "Wir speichern das erzeugte DataFrame in die Datei `city_system_lengths.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753155df",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_system_lengths.drop(columns=['length_km', 'diff_abs']).to_csv('data/city_system_lengths.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f7f44",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>ÜBUNG: </b> Pivot-Tabelle\n",
    "    <ol><li>Erstellen Sie eine neue Spalte in cities, das die Längen in Kategorien einteilt ('kurz', wenn im unteresten Quartil, 'normal', wenn im 2. oder 3. Quartil, sonst 'lang')</li>\n",
    "        <li>Erstellen Sie eine Pivot-Tabelle mit Ländern als Zeilen und Längenkategorien als Spalten - die Werte soll die Anzahl der Städte sein</li>\n",
    "        <li>Erstellen Sie ein <a href=\"https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_stacked.html#sphx-glr-gallery-lines-bars-and-markers-bar-stacked-py\">stacked Bar Chart</a></li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad7ccc1",
   "metadata": {},
   "source": [
    "## Spalten in Zeilen umwandeln (melt)\n",
    "\n",
    "Die umgekehrte Operation zum Pivotieren ist `melt`. Hierbei können Werte in Spalten in separate Zeilen umgewandelt werden. Standardmäßig werden alle Spalten zu Zeilen gemacht - der ursprüngliche Zeilenverbund geht verloren. Mit dem Parameter `id_vars` können Spalten angeben werden, die weiterhin als Spalten übernommen werden und die Zusammengehörigkeit verschiedener Spalten herstellt.\n",
    "\n",
    "Das einfachste Beispiel ist, wenn wir eine vorherige Pivotierung rückgänging machen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = city_system_lengths.drop(columns=['total', 'length_km', 'diff_abs'])\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted.melt(id_vars=['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a88307",
   "metadata": {},
   "source": [
    "Schauen wir uns komplexeres Beispiel an: die geometrischen Punkte der Sections. Diese sind als String abgespeichert, wo die einzelnen Punkte per Komma separiert sind. Um die einzelnen Koordinaten zu bekommen, können wir per `.str.split` die Koordinaten in Spalten umwandeln und dann mit melt eine Zeile pro Koordinate bilden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b312347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice entfernt \"LINESTRING\" und die schliessende Klammer\n",
    "# Split erzeugt eine neue Spalte\n",
    "section_paths = sections['geometry'].str.slice(11,-1).str.split(',', expand=True)\n",
    "section_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nun wandeln wir Spalten in Zeilen um\n",
    "# Die Spaltennamen werden nun die Reihenfolge der Punkte\n",
    "# In der gleichen Zeile entfernen wir None Werte - diese\n",
    "# entstehen weil die Anzahl der Spalten nach der Section\n",
    "# mit den meisten Punkten bestimmt wurde\n",
    "section_paths = section_paths.melt(ignore_index=False).dropna()\n",
    "# section_id aus Index in Spalte\n",
    "section_paths.reset_index(inplace=True)\n",
    "section_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nun splitten wir nach long und lat\n",
    "long_lats = section_paths['value'].str.split(' ', expand=True)\n",
    "# Convert long/lat to number or NaN if not a valid number and add to DataFrame\n",
    "section_paths['long'] = pd.to_numeric(long_lats[0], errors='coerce')\n",
    "section_paths['lat'] = pd.to_numeric(long_lats[1], errors='coerce')\n",
    "# Drop errors\n",
    "section_paths.dropna(inplace=True)\n",
    "# Drop Textual Column\n",
    "section_paths.drop(columns=['value'], inplace=True)\n",
    "# Und sortieren erst nach id und Variable \n",
    "section_paths.sort_values(['id', 'variable'], inplace=True)\n",
    "section_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b53613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benennen der Spalten\n",
    "section_paths.columns = ['section_id', 'order', 'long', 'lat']\n",
    "section_paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bfd68",
   "metadata": {},
   "source": [
    "Die matplotlib Funktion `plot` zeichnet Linien entlang Punkten, wenn als erster Parameter, die x-Koordinaten und als zweiter Parameter, die y-Koordinaten übergeben werden. Dies nutzen wir, indem wir für eine Section sämtliche Koordinaten auswählen, dann das Array transposen und mit dem `*`-Operator die Einträge als Parameter zur Plot-Funktion übergeben. Wir schreiben eine Funktion, die dies für alle Sections einer gegebenen Stadt macht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Sections of City by name\n",
    "\n",
    "def draw_sections(cityname):\n",
    "    city_id = cities[cities['name'] == cityname].index.values[0]\n",
    "\n",
    "    for section_id in sections[sections['city_id'] == city_id].index:\n",
    "        plt.plot(*section_paths.loc[section_paths['section_id'] == section_id, 'long':'lat'].values.T)\n",
    "\n",
    "    plt.title('Public transport sections of ' + cityname)\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55084465",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_sections('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9351aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_sections('New York')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
